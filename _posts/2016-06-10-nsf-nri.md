---
layout: post
title: CoSTAR at the NRI 5th Anniversary Event
---

I flew back to Baltimore to help with our presentation at the Rayburn Congressional Office Building in DC yesterday. This was definitely an interesting experience; we got to meet a very different set of people from at an industry event like Hannover Messe or a robotics conference like IROS.

We put together a more complex structure assembly demo to show off CoSTAR:

<iframe width="560" height="315" src="https://www.youtube.com/embed/m86kPDYGNho" frameborder="0" allowfullscreen></iframe>

A procedure like this one is composed of many different reusable sections, which is part of why a framework like this is so powerful. To build this task, we first created a number of actions corresponding to moving out of the way and detecting objects, picking up and placing the node, picking up the link, and so on.

![Tree for detecting, picking up, and placing node]({{site.baseurl}}public/training1.png)

We have to combine this into a fairly complex tree to complete this assembly task.

![Full tree]({{site.baseurl}}public/training2.png)

We also demonstrated a task that was very similar to one from Hannover MesseL we had the robot pickup blocks and hand them to the human when the human signaled that they were ready for a part. This relies on our very simple occupancy detector, a piece of code you can find in [Predicator](https://github.com/cpaxton/predicator) and as a part of the full [CoSTAR stack](https://github.com/cpaxton/costar_stack). The occupancy detector is about the simplest "activity recognition" you can imagine: we specify a volume in space and trigger an event if that volume contains more points than a particular threshold.

![Felix setting up the demo at Rayburn]({{site.baseurl}}public/nri2016-felix)

We were able to get our demos set up despite forgetting the circular platform we used to train the procedure. We had two problems in particular: (1) the [object detection code](https://github.com/jhu-lcsr/sp_segmenter) is somewhat sensitive to changes in lighting, and we saw a lot of glare from the lights in Rayburn that threw it off; and (2) our UR5 has kinematics that are somewhat limited by the gripper and other attachments, so most of the grasps we taught it were at too low an angle without the platform. Still, the power of CoSTAR is that even when things don't work at first, you can problem solve!

<iframe width="560" height="315" src="https://www.youtube.com/embed/u07PonCHMys" frameborder="0" allowfullscreen></iframe>

We had a lot of interest at the NRI event. This mirrors my experience at Hannover Messe: making robots more intelligent and easier to use is something almost everyone is interested in. People and robots working side by side is definitely the future, and this was an exciting event.
