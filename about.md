---
layout: page
permalink: /about/index.html
title: About Me
tags: [about, Chris, Paxton, Chris Paxton]
categories: [about]
chart: true
---

I am a robotics research scientist interested in ways we can allow non-expert users to give robots the knowledge they need to be able to plan and adapt to new and unseen situations. Effectively, I am interested in making robots into true co-workers complete with "common sense" that allows them to do the parts of a task that are difficult for humans.

My work focuses on integrating symbolic task planning with deep learning from experts. The goal is to give robots "common sense" and let them intelligently interact with their environments. The most recent incarnation of this project is our new work on creating "robots with imagination" -- letting robots learn about the consequences their actions will have for the world, and being able to plan based on these imagined actions.

I got my PhD in Computer Science at the Johns Hopkins University in Baltimore, Maryland, focusing on using learning to create powerful task and motion planning capabilities for robots operating in human environments.
Since graduating, I have been with NVIDIA, at their [Seattle robotics lab](https://youtu.be/JT2viTz_0jU). I have been working on approaches that tie together language, perception, and action, in order to make robots into robust, versatile assistants for a variety of applications.

<!--<img style="float: right;" src="{{ site.url }}/images/me.jpg">-->

You can also check out [My NVIDIA Research profile](https://research.nvidia.com/person/chris-paxton), or find a list of my papers on [Google Scholar](https://scholar.google.com/citations?user=I1mOQpAAAAAJ&hl=en&oi=ao).

### News and Links

  * [NVIDIA Researchers Use AI to Teach Robots How to Improve Human-to-Robot Interactions - NVIDIA](https://news.developer.nvidia.com/nvidia-researchers-use-ai-to-teach-robots-how-to-improve-human-to-robot-interactions/)
  * [NVIDIA researchers use AI to teach robots how to hand objects to humans - VentureBeat](https://venturebeat.com/2020/03/16/nvidia-researchers-use-ai-to-teach-robots-how-to-hand-objects-to-humans/)
  * [Video Feature on the Seattle Robotics Lab](https://youtu.be/JT2viTz_0jU)
  * [NVIDIA Opens Robotics Research Lab in Seattle](https://news.developer.nvidia.com/nvidia-opens-robotics-research-lab-in-seattle/)
  * [JHU Robotics Team Wins KUKA Innovation Award - MD](https://open.maryland.gov/blog/jhu-robotics-team-wins-kuka-innovation-award/) - invited blog post by me
  * [The finalists of the Innovation Award 2016 have been selected - KUKA](http://www.kuka-robotics.com/en/pressevents/news/NN_14012016_Innovative_Robot_applications_LBR_iiwa.htm)
  * [KUKA Innovation Award 2016: Flexible Manufacturing Challenge - KUKA](https://www.kuka.com/en-DE/Press/Event%20calendar/Hannover%20Fair%202016/kuka-innovation-award)
  
### Papers

  * [Human Grasp Classification for Reactive Human-to-Robot Handovers](https://arxiv.org/pdf/2003.06000)
  * [Transferable Task Execution from Pixels through Deep Planning Domain Learning](https://arxiv.org/pdf/2003.03726) - ICRA 2020 - Paris, France
  * [6-DOF Grasping for Target-driven Object Manipulation in Clutter](https://arxiv.org/pdf/1912.03628) - ICRA 2020 - Paris, France
  * [Motion Reasoning for Goal-Based Imitation Learning](https://arxiv.org/pdf/1911.05864) - ICRA 2020 - Paris, France
  * [Online Replanning in Belief Space for Partially Observable Task and Motion Problems](https://arxiv.org/pdf/1911.04577) - ICRA 2020 - Paris, France
  * [Conditional Driving from Natural Language Insturctions](https://arxiv.org/pdf/1910.07615) - CoRL 2019 - Osaka, Japan
  * [Representing Robot Task Plans as Robust Logical-Dynamical Systems](https://arxiv.org/pdf/1908.01896) - IROS 2019 - Macau SAR, China
  * [The CoSTAR Block Stacking Dataset: Learning with Workspace Constraints](https://arxiv.org/pdf/1810.11714.pdf) - IROS 2019 - Macau SAR, China
  * [Visual Robot Task Planning](https://arxiv.org/pdf/1804.00062) - ICRA 2019 - Montreal, Canada
  * [Evaluating Methods for End-User Creation of Robot Task Plans](https://arxiv.org/pdf/1811.02690) - IROS 2018 - Madrid, Spain
  * [Combining neural networks and tree search for task and motion planning in challenging environments](https://arxiv.org/pdf/1703.07887) - IROS 2017 - Vancouver, Canada
  * [CoSTAR in Surgery: A Cross-platform User Interface for Surgical Robot Task Specification](https://pdfs.semanticscholar.org/b853/81226292ed8a47cb4e059ced14ddcc6ea798.pdf) - IROS 2017 Workshop - Vancouver, Canada
  * [CoSTAR: Instructing Collaborative Robots through Behavior Trees and Vision](https://arxiv.org/pdf/1611.06145) - ICRA 2017 - Singapore
  * [Do What I Want, Not What I Did: Imitation of Skills by Planning Sequences of Actions](https://arxiv.org/pdf/1612.01215) - IROS 2016 - Daejeon, Korea
  * [Semi-autonomous telerobotic assembly over high-latency networks](https://dl.acm.org/ft_gateway.cfm?ftid=1702218&id=2906858) - HRI 2016 - New Zealand
  * [Towards Robot Task Planning From Probabilistic Models of Human Skills](https://arxiv.org/pdf/1602.04754) - AAAI 2016 workshop - Phoenix, USA
  * [An incremental approach to learning generalizable robot tasks from human demonstration](http://eprints.lincoln.ac.uk/34493/1/ICRA15_0728_FI.pdf) - ICRA 2015 - Seattle, USA
  * [A framework for end-user instruction of a robot assistant for manufacturing](https://ieeexplore.ieee.org/iel7/7128761/7138973/07140065.pdf?casa_token=mrp6oZcPvy4AAAAA:ux_-Jq6IHKCmjodjywSvdBiQyHcoeQrd-M45MfuPOTVdZxjGHEMuS3YbqLeO2Kh2XCTRl8r4xBCO) - ICRA 2015 - Seattle, USA
  * [Developing predictive models using electronic medical records: challenges and pitfalls](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3900132/) - AMIA - Washington, USA

### Patents

  * [Trajectory Generation using Temporal Logic and Tree Search](https://patentimages.storage.googleapis.com/35/dc/4e/6bf9a63a604604/US10133275.pdf)

## Work Experience

  * Robotics Research Scientist, NVIDIA (2019-present)
  * Postdoc at NVIDIA, in their new Seattle Robotics Lab (2018-2019)
  * PhD student at Johns Hopkins University (2012-2018)
  * Co-op at Zoox (2016-2017): planning for autonomous vehicles
  * Lockheed Martin (Summer 2012): security with mobile devices
  * US Army Research Lab (2010-2012): pedestrian detection
  * Johns Hopkins Applied Physics Lab: development of a zero gravity robot prototype

## Education

As of Spring 2018, I successfully defended my PhD in Computer Science at the Johns Hopkins University in Baltimore, Maryland. My PhD thesis is titled "Creating Task Plans for Collaborative Robots," and it covers both our CoSTAR system and the novel algorithms we have created for creating robots that can use expert knowledge to plan.

I did my undergraduate work at University of Maryland, College Park, where I got a BS in Computer Science with a minor in Neuroscience, where I graduated with University honors as a part of their Gemstone program for young researchers.

During Spring 2016, I led the JHU team for the KUKA Innovation Award competition. I led our successful entry into the KUKA innovation award competition with our updated [CoSTAR system](http://cpaxton.github.io/costar_stack/). CoSTAR integrates a user interface, perception, and abstract planning to create robust task plans. We have since used CoSTAR on a wide variety of problems.

<figure>
  <img src="{{ site.url }}/public/kuka2016.jpg" alt="Finalists at KUKA College Gersthofen">
  <figcaption>KUKA award finalists at KUKA College Gersthofen in December 2015.</figcaption>
</figure>

### Education Links
  * [Computational Interaction and Robotics Lab](http://cirl.lcsr.jhu.edu/)
  * [The finalists of the Innovation Award 2016 have been selected](http://www.kuka-robotics.com/en/pressevents/news/NN_14012016_Innovative_Robot_applications_LBR_iiwa.htm)
  * [KUKA Innovation Award 2016: Flexible Manufacturing Challenge](https://www.kuka.com/en-DE/Press/Event%20calendar/Hannover%20Fair%202016/kuka-innovation-award)

## Teaching Experience

  * Teaching assistant for EN.600.436/636: __"Algorithms for Sensor Based Robotics"__, Spring 2015
  * Taught EN.500.111 __"HEART: Making Robots our Friends: Technologies for Human-Robot Collaboration"__ in Fall 2015.
