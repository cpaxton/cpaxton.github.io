---
layout: page
permalink: /about/index.html
title: About Me
tags: [about, Chris, Paxton, Chris Paxton]
categories: [about]
chart: true
---

I am a robotics research scientist at NVIDIA. I'm interested in ways we can allow robots to work alongside humans to perform complex, multi-step tasks, using a combination of learning and planning.

I got my PhD in Computer Science in 2018 from the Johns Hopkins University in Baltimore, Maryland, focusing on using learning to create powerful task and motion planning capabilities for robots operating in human environments.
Since then, I have been with NVIDIA, at their [Seattle robotics lab](https://youtu.be/JT2viTz_0jU). Recently, I have been working on approaches that tie together language, perception, and action, in order to make robots into robust, versatile assistants for a variety of applications. Other areas of interest include [human-robot interaction](https://www.youtube.com/watch?v=I7mAoEJHee4&feature=youtu.be).

<!--<img style="float: right;" src="{{ site.url }}/images/me.jpg">-->

You can also check out [My NVIDIA Research profile](https://research.nvidia.com/person/chris-paxton), find a list of my papers on [Google Scholar](https://scholar.google.com/citations?user=I1mOQpAAAAAJ&hl=en&oi=ao), or email me at chris.paxton.cs (at) gmail.com.

### News and Links

  * [ALFRED Challenge results - CVPR 2021 - my team in 1st place](https://askforalfred.com/EAI21/) - ALFRED
  * [Makerâ€™s Dozen: NVIDIA Researchers to Present Advances in Human-Robot Interaction and More at ICRA](https://blogs.nvidia.com/blog/2021/05/27/human-robot-interaction-research-icra) - NVIDIA
  * [BBC: Dog training technique helps robot learn and other news](https://www.bbc.com/news/av/technology-54645279) - BBC
  * [Teaching Robots through Positive Reinforcement](https://techcrunch.com/2020/10/26/teaching-robots-through-positive-reinforcement/) - TechCrunch
  * [New AI Trains Robots like Dogs](https://www.psychologytoday.com/us/blog/the-future-brain/202010/new-ai-trains-robots-dogs) - Psychology Today
  * [Dog Training Methods Help JHU Teach Robots to Learn New Tricks](https://cacm.acm.org/news/248390-dog-training-methods-help-jhu-teach-robots-to-learn-new-tricks/fulltext) - Communications of the ACM
  * [Robotics Reaps Rewards at ICRA](https://blogs.nvidia.com/blog/2020/05/29/dieter-fox-award-icra/) - NVIDIA
  * [NVIDIA Researchers Use AI to Teach Robots How to Improve Human-to-Robot Interactions](https://news.developer.nvidia.com/nvidia-researchers-use-ai-to-teach-robots-how-to-improve-human-to-robot-interactions/) - NVIDIA
  * [NVIDIA researchers use AI to teach robots how to hand objects to humans](https://venturebeat.com/2020/03/16/nvidia-researchers-use-ai-to-teach-robots-how-to-hand-objects-to-humans/) - VentureBeat
  * [Video Feature on the Seattle Robotics Lab](https://youtu.be/JT2viTz_0jU)
  * [NVIDIA Opens Robotics Research Lab in Seattle](https://news.developer.nvidia.com/nvidia-opens-robotics-research-lab-in-seattle/) - NVIDIA
  * [JHU Robotics Team Wins KUKA Innovation Award - MD](https://open.maryland.gov/blog/jhu-robotics-team-wins-kuka-innovation-award/) - Invited blog post by me
  * [The finalists of the Innovation Award 2016 have been selected](http://www.kuka-robotics.com/en/pressevents/news/NN_14012016_Innovative_Robot_applications_LBR_iiwa.htm) - KUKA
  * [KUKA Innovation Award 2016: Flexible Manufacturing Challenge](https://www.kuka.com/en-DE/Press/Event%20calendar/Hannover%20Fair%202016/kuka-innovation-award) - KUKA
  
### Papers

  * [Automated Generation of Robotic Planning Domains from Observations](https://arxiv.org/pdf/2105.13604.pdf) - IROS 2021
  * [Sim-to-Real Task Planning and Execution from Perception via Reactivity and Recovery](https://arxiv.org/abs/2011.08694) ([video](https://youtu.be/qbCzYgAW86w)) ([experiments](https://www.youtube.com/playlist?list=PL-oD0xHUngeLfQmpngYkGFZarstfPOXqX)) - IROS 2021
  * [NeRP: Neural Rearrangement Planning for Unknown Objects](https://arxiv.org/pdf/2106.01352) - RSS 2021
  * [Reactive Human-to-Robot Handovers of Arbitrary Objects](https://arxiv.org/abs/2011.08961) ([video](https://youtu.be/ZfibF9UNCrw)) ([website](https://arxiv.org/abs/2011.08961)) - ICRA 2021 Best HRI Paper *winner*
  * [Alternate Paths Planner (APP) for Provably Fixed-time Manipulation Planning in Semi-Structured Environments](https://arxiv.org/abs/2012.14970) - ICRA 2021
  * ["Good Robot!": Efficient Reinforcement Learning for Multi-Step Visual Tasks with Sim to Real Transfer](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9165109) ([video](https://www.youtube.com/watch?v=qivDFfPf9_I)) - IROS+RAL 2020
  * [Human Grasp Classification for Reactive Human-to-Robot Handovers](https://arxiv.org/pdf/2003.06000) ([video](https://www.youtube.com/watch?v=I7mAoEJHee4&feature=youtu.be)) - IROS 2020
  * [Collaborative Behavior Models for Optimized Human-Robot Teamwork](https://arxiv.org/pdf/1910.04339.pdf) ([video](https://www.youtube.com/watch?v=bSY8K-jkRtA)) - IROS 2020
  * [Transferable Task Execution from Pixels through Deep Planning Domain Learning](https://arxiv.org/pdf/2003.03726) - ICRA 2020
  * [6-DOF Grasping for Target-driven Object Manipulation in Clutter](https://arxiv.org/pdf/1912.03628) ([video](https://youtu.be/nVpiMzIj0-c)) - ICRA 2020
  * [Motion Reasoning for Goal-Based Imitation Learning](https://arxiv.org/pdf/1911.05864) - ICRA 2020
  * [Online Replanning in Belief Space for Partially Observable Task and Motion Problems](https://arxiv.org/pdf/1911.04577) ([video](https://www.youtube.com/watch?v=IOtrO29DFUg&list=PLNpZKR7uv5ARTi1sNQRcd5rpa8XxamW2l)) ([presentation](https://www.youtube.com/watch?v=gdTWHjIC-9s)) - ICRA 2020
  * [Conditional Driving from Natural Language Instructions](https://arxiv.org/pdf/1910.07615) - CoRL 2019
  * [Representing Robot Task Plans as Robust Logical-Dynamical Systems](https://arxiv.org/pdf/1908.01896) - IROS 2019
  * [The CoSTAR Block Stacking Dataset: Learning with Workspace Constraints](https://arxiv.org/pdf/1810.11714.pdf) - IROS 2019
  * [Visual Robot Task Planning](https://arxiv.org/pdf/1804.00062) - ICRA 2019
  * [Evaluating Methods for End-User Creation of Robot Task Plans](https://arxiv.org/pdf/1811.02690) - IROS 2018
  * [Combining neural networks and tree search for task and motion planning in challenging environments](https://arxiv.org/pdf/1703.07887) - IROS 2017
  * [CoSTAR in Surgery: A Cross-platform User Interface for Surgical Robot Task Specification](https://pdfs.semanticscholar.org/b853/81226292ed8a47cb4e059ced14ddcc6ea798.pdf) - IROS 2017 workshop
  * [CoSTAR: Instructing Collaborative Robots through Behavior Trees and Vision](https://arxiv.org/pdf/1611.06145) - ICRA 2017
  * [Do What I Want, Not What I Did: Imitation of Skills by Planning Sequences of Actions](https://arxiv.org/pdf/1612.01215) - IROS 2016
  * [Semi-autonomous telerobotic assembly over high-latency networks](https://dl.acm.org/ft_gateway.cfm?ftid=1702218&id=2906858) - HRI 2016
  * [Towards Robot Task Planning From Probabilistic Models of Human Skills](https://arxiv.org/pdf/1602.04754) - AAAI 2016 workshop
  * [An incremental approach to learning generalizable robot tasks from human demonstration](http://eprints.lincoln.ac.uk/34493/1/ICRA15_0728_FI.pdf) - ICRA 2015
  * [A framework for end-user instruction of a robot assistant for manufacturing](https://ieeexplore.ieee.org/iel7/7128761/7138973/07140065.pdf?casa_token=mrp6oZcPvy4AAAAA:ux_-Jq6IHKCmjodjywSvdBiQyHcoeQrd-M45MfuPOTVdZxjGHEMuS3YbqLeO2Kh2XCTRl8r4xBCO) - ICRA 2015
  * [Developing predictive models using electronic medical records: challenges and pitfalls](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3900132/) - AMIA 2013

### Patents

  * [Robot Control using Deep Learning](https://www.freepatentsonline.com/y2021/0252698.html)
  * [Imitation Learning System](https://patentimages.storage.googleapis.com/03/ba/22/79fd056c7334f5/US20210081752A1.pdf)
  * [Trajectory Generation using Temporal Logic and Tree Search](https://patentimages.storage.googleapis.com/35/dc/4e/6bf9a63a604604/US10133275.pdf)

### Invited Talks

  * Connecting TAMP to the Real World ([video](https://www.youtube.com/watch?v=Zzi29kSKlcE)) - [RSS 2020 Worksop on Learning in Task and Motion Planning](https://ipvs.informatik.uni-stuttgart.de/mlr/rss2020Workshop/)
  * From Pixels to Task Planning and Execution - [IROS 2019 Workshop on Semantic Policis and Action Representations](https://sites.google.com/view/spar2019/speakers?authuser=0)
  * Building Reactive Task Plans for Real-World Robot Applications - [IROS 2019 Workshop on Behavior Trees for Robotic Systems](https://behavior-trees-iros-workshop.github.io/)

## Work Experience

  * Senior Robotics Research Scientist , NVIDIA (2020-present)
  * Robotics Research Scientist, NVIDIA (2019-2020)
  * Postdoc at NVIDIA, in their Seattle Robotics Lab (2018-2019)
  * PhD student at Johns Hopkins University (2012-2018): represening tasks for collaborative robots 
  * Research Engineer Co-op at Zoox (2016-2017): planning for autonomous vehicles
  * Lockheed Martin (Summer 2012): security with mobile devices
  * US Army Research Lab (2010-2012): pedestrian detection
  * Johns Hopkins Applied Physics Lab: development of a zero gravity robot prototype

## Education

As of Spring 2018, I successfully defended my PhD in Computer Science at the Johns Hopkins University in Baltimore, Maryland. My PhD thesis is titled [Creating Task Plans for Collaborative Robots](https://jscholarship.library.jhu.edu/handle/1774.2/59196), and it covers both our CoSTAR system and the novel algorithms we have created for creating robots that can use expert knowledge to plan. I did my research in the [Computational Interaction and Robotics Lab](http://cirl.lcsr.jhu.edu/) with Greg Hager.

I did my undergraduate work at University of Maryland, College Park, where I got a BS in Computer Science with a minor in Neuroscience, where I graduated with University honors as a part of their Gemstone program for young researchers.

During Spring 2016, I led the JHU team for the KUKA Innovation Award competition. I led our successful entry into the KUKA innovation award competition with our updated [CoSTAR system](http://cpaxton.github.io/costar_stack/). CoSTAR integrates a user interface, perception, and abstract planning to create robust task plans. We have since used CoSTAR on a wide variety of problems.

<figure>
  <img src="{{ site.url }}/public/kuka2016.jpg" alt="Finalists at KUKA College Gersthofen">
  <figcaption>KUKA award finalists at KUKA College Gersthofen in December 2015.</figcaption>
</figure>

## Teaching Experience

  * Taught EN.500.111 __"HEART: Making Robots our Friends: Technologies for Human-Robot Collaboration"__ in Fall 2015.
  * Teaching assistant for EN.600.436/636: __"Algorithms for Sensor Based Robotics"__, Spring 2015
