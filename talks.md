

## From Pixels to Task Planning and Execution

IROS 2019 Workshop on Semantic Policis and Action Representations

In order for robots to act intelligently in human environments, they must be able to connect multiple primitive actions together to accomplish new long-term goals through the composition of primitive skills. Our goal is to learn representations that can be used with task planning, with the goal being to enable generalization of learned behaviors to new tasks and new environments using sensor data. We propose Deep Planning Domain Learning to capture the preconditions and effects of various actions, which allows us to search for goal states. The representation learned by DPDL can be used for high-level task planning, and also gives us a set of low-level policies for task execution, all from sensor data. These methods bring us closer to the goal of general-purpose robots operating on sensor data in human environments.


## Building Reactive Task Plans for Real-World Robot Applications

IROS 2019 Workshop on Behavior Trees for Robotic Systems

Robots are increasingly an important part of our world, from working in factories and hospitals to driving on city streets. As robots move into more unstructured environments such as homes, however, we must be able to create complex, reactive task plans that can deal with stochastic actions, unreliable sensors, and that above all are intuitive and easy to build. To this end, we created the Behavior Tree-based CoSTAR system -- which allows novice end users to create task plans for industrial robot task plans, shown in a 35-person user study to be highly user friendly and offer a useful set of tools for creating task plans. We also describe a variant on Behavior Trees, the Robust Logical-Dynamical System (RLDS), which supports symbolic task planning and guarantees on performance. Finally, we describe a manipulation case study on an example of an unstructured household manipulation task.


